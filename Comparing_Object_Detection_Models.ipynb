{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1Ydr5_nDgoymKEf22ihs2F0AtdtU6LPbX",
      "authorship_tag": "ABX9TyPmswdyvHAWhbpVFiIgvRqs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnzambuli/Deep-learning-4-CV/blob/master/Comparing_Object_Detection_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ys6fh3872t2S",
        "outputId": "0d6e59d9-37ae-4802-cb1e-4819a721e364"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Task:** Train an object detection model on a given dataset and evaluate its performance. Compare its performance with other models trained on the dataset.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. Choose a dataset (e.g., COCO, PASCAL VOC, or a custom dataset).\n",
        "2. Select an object detection framework (e.g., Faster R-CNN, YOLO).\n",
        "3. Train the model and optimize hyperparameters.\n",
        "4. Evaluate using precision, recall, and mAP.\n",
        "5. Compare performance with another model.\n",
        "\n",
        "📌 **Deliverables:**\n",
        "\n",
        "1. Trained model files\n",
        "2. Performance evaluation report\n",
        "3. Comparison with at least one other object detection model\n"
      ],
      "metadata": {
        "id": "1BVtQy6jhOV2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fiftyone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JhjOuPnjoNa5",
        "outputId": "8a8aac31-6c92-40fb-ff6d-f081e69b2164"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fiftyone\n",
            "  Downloading fiftyone-1.3.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting aiofiles (from fiftyone)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting argcomplete (from fiftyone)\n",
            "  Downloading argcomplete-3.5.3-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from fiftyone) (4.13.3)\n",
            "Collecting boto3 (from fiftyone)\n",
            "  Downloading boto3-1.36.21-py3-none-any.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from fiftyone) (5.5.1)\n",
            "Collecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n",
            "  Downloading dacite-1.7.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: Deprecated in /usr/local/lib/python3.11/dist-packages (from fiftyone) (1.2.18)\n",
            "Collecting ftfy (from fiftyone)\n",
            "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.11/dist-packages (from fiftyone) (4.11.0)\n",
            "Collecting hypercorn>=0.13.2 (from fiftyone)\n",
            "  Downloading hypercorn-0.17.3-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: Jinja2>=3 in /usr/local/lib/python3.11/dist-packages (from fiftyone) (3.1.5)\n",
            "Collecting kaleido!=0.2.1.post1 (from fiftyone)\n",
            "  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl.metadata (15 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from fiftyone) (3.10.0)\n",
            "Collecting mongoengine~=0.29.1 (from fiftyone)\n",
            "  Downloading mongoengine-0.29.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting motor~=3.6.0 (from fiftyone)\n",
            "  Downloading motor-3.6.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from fiftyone) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from fiftyone) (24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from fiftyone) (2.2.2)\n",
            "Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.11/dist-packages (from fiftyone) (11.1.0)\n",
            "Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.11/dist-packages (from fiftyone) (5.24.1)\n",
            "Collecting pprintpp (from fiftyone)\n",
            "  Downloading pprintpp-0.4.0-py2.py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from fiftyone) (5.9.5)\n",
            "Collecting pymongo~=4.9.2 (from fiftyone)\n",
            "  Downloading pymongo-4.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.11/dist-packages (from fiftyone) (2025.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from fiftyone) (6.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from fiftyone) (2024.11.6)\n",
            "Collecting retrying (from fiftyone)\n",
            "  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting rtree (from fiftyone)\n",
            "  Downloading Rtree-1.3.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from fiftyone) (1.6.1)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (from fiftyone) (0.25.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from fiftyone) (1.13.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from fiftyone) (75.1.0)\n",
            "Collecting sseclient-py<2,>=1.7.2 (from fiftyone)\n",
            "  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting sse-starlette<1,>=0.10.3 (from fiftyone)\n",
            "  Downloading sse_starlette-0.10.3-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting starlette>=0.24.0 (from fiftyone)\n",
            "  Downloading starlette-0.45.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting strawberry-graphql (from fiftyone)\n",
            "  Downloading strawberry_graphql-0.260.2-py3-none-any.whl.metadata (7.5 kB)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.11/dist-packages (from fiftyone) (0.9.0)\n",
            "Collecting xmltodict (from fiftyone)\n",
            "  Downloading xmltodict-0.14.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Collecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n",
            "  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl.metadata (5.5 kB)\n",
            "Collecting pydash (from fiftyone)\n",
            "  Downloading pydash-8.0.5-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting fiftyone-brain<0.20,>=0.19.0 (from fiftyone)\n",
            "  Downloading fiftyone_brain-0.19.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Collecting fiftyone-db<2.0,>=0.4 (from fiftyone)\n",
            "  Downloading fiftyone_db-1.1.7.tar.gz (7.9 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting voxel51-eta<0.15,>=0.14.0 (from fiftyone)\n",
            "  Downloading voxel51_eta-0.14.0-py2.py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.11/dist-packages (from fiftyone) (4.11.0.86)\n",
            "Requirement already satisfied: h11 in /usr/local/lib/python3.11/dist-packages (from hypercorn>=0.13.2->fiftyone) (0.14.0)\n",
            "Requirement already satisfied: h2>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from hypercorn>=0.13.2->fiftyone) (4.2.0)\n",
            "Collecting priority (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading priority-2.0.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3->fiftyone) (3.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=4.14->fiftyone) (9.0.0)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo~=4.9.2->fiftyone) (2.7.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette>=0.24.0->fiftyone) (3.7.1)\n",
            "Requirement already satisfied: httpx>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from universal-analytics-python3<2,>=1.0.1->fiftyone) (0.28.1)\n",
            "Collecting dill (from voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from voxel51-eta<0.15,>=0.14.0->fiftyone) (1.0.0)\n",
            "Requirement already satisfied: glob2 in /usr/local/lib/python3.11/dist-packages (from voxel51-eta<0.15,>=0.14.0->fiftyone) (0.7)\n",
            "Collecting jsonlines (from voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting py7zr (from voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from voxel51-eta<0.15,>=0.14.0->fiftyone) (2.8.2)\n",
            "Collecting rarfile (from voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading rarfile-4.2-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from voxel51-eta<0.15,>=0.14.0->fiftyone) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from voxel51-eta<0.15,>=0.14.0->fiftyone) (1.17.0)\n",
            "Collecting sortedcontainers (from voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: tzlocal in /usr/local/lib/python3.11/dist-packages (from voxel51-eta<0.15,>=0.14.0->fiftyone) (5.2)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.11/dist-packages (from voxel51-eta<0.15,>=0.14.0->fiftyone) (2.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->fiftyone) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->fiftyone) (4.12.2)\n",
            "Collecting botocore<1.37.0,>=1.36.21 (from boto3->fiftyone)\n",
            "  Downloading botocore-1.36.21-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting jmespath<2.0.0,>=0.7.1 (from boto3->fiftyone)\n",
            "  Downloading jmespath-1.0.1-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting s3transfer<0.12.0,>=0.11.0 (from boto3->fiftyone)\n",
            "  Downloading s3transfer-0.11.2-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->fiftyone) (1.17.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->fiftyone) (0.2.13)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fiftyone) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fiftyone) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fiftyone) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fiftyone) (1.4.8)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->fiftyone) (3.2.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->fiftyone) (2025.1)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image->fiftyone) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image->fiftyone) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image->fiftyone) (2025.1.10)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image->fiftyone) (0.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->fiftyone) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->fiftyone) (3.5.0)\n",
            "Collecting graphql-core<3.4.0,>=3.2.0 (from strawberry-graphql->fiftyone)\n",
            "  Downloading graphql_core-3.2.6-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette>=0.24.0->fiftyone) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette>=0.24.0->fiftyone) (1.3.1)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.11/dist-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.11/dist-packages (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone) (4.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (1.0.7)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonlines->voxel51-eta<0.15,>=0.14.0->fiftyone) (25.1.0)\n",
            "Collecting texttable (from py7zr->voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting pycryptodomex>=3.16.0 (from py7zr->voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Collecting pyzstd>=0.15.9 (from py7zr->voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n",
            "Collecting pyppmd<1.2.0,>=1.1.0 (from py7zr->voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading pybcj-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\n",
            "Collecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
            "Collecting brotli>=1.1.0 (from py7zr->voxel51-eta<0.15,>=0.14.0->fiftyone)\n",
            "  Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->voxel51-eta<0.15,>=0.14.0->fiftyone) (3.4.1)\n",
            "Downloading fiftyone-1.3.0-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dacite-1.7.0-py3-none-any.whl (12 kB)\n",
            "Downloading fiftyone_brain-0.19.0-py3-none-any.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.7/99.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hypercorn-0.17.3-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mongoengine-0.29.1-py3-none-any.whl (112 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/112.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading motor-3.6.1-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pymongo-4.9.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n",
            "Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n",
            "Downloading starlette-0.45.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n",
            "Downloading voxel51_eta-0.14.0-py2.py3-none-any.whl (942 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m943.0/943.0 kB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Downloading argcomplete-3.5.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading boto3-1.36.21-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n",
            "Downloading pydash-8.0.5-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.1/102.1 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n",
            "Downloading Rtree-1.3.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (543 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m543.2/543.2 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading strawberry_graphql-0.260.2-py3-none-any.whl (295 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xmltodict-0.14.2-py2.py3-none-any.whl (10.0 kB)\n",
            "Downloading botocore-1.36.21-py3-none-any.whl (13.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.6-py3-none-any.whl (203 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.4/203.4 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
            "Downloading s3transfer-0.11.2-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Downloading dill-0.3.9-py3-none-any.whl (119 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n",
            "Downloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rarfile-4.2-py3-none-any.whl (29 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Downloading Brotli-1.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading inflate64-1.0.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (96 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
            "Downloading pybcj-1.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.21.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyppmd-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.3/141.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyzstd-0.16.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Building wheels for collected packages: fiftyone-db\n",
            "  Building wheel for fiftyone-db (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fiftyone-db: filename=fiftyone_db-1.1.7-py3-none-manylinux1_x86_64.whl size=42156214 sha256=1cf0e95301dca643273bd8a520a9db743740a180b25a3bd12c10ef045f611a3b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bf/75/da/54cd52c92db9f0c4e88ca5efdbac2304b49927249c9c859b8d\n",
            "Successfully built fiftyone-db\n",
            "Installing collected packages: texttable, sseclient-py, sortedcontainers, pprintpp, kaleido, brotli, xmltodict, wsproto, rtree, retrying, rarfile, pyzstd, pyppmd, pymongo, pydash, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, inflate64, graphql-core, ftfy, fiftyone-db, dill, dacite, argcomplete, aiofiles, strawberry-graphql, starlette, py7zr, motor, mongoengine, hypercorn, botocore, voxel51-eta, universal-analytics-python3, sse-starlette, s3transfer, fiftyone-brain, boto3, fiftyone\n",
            "Successfully installed aiofiles-24.1.0 argcomplete-3.5.3 boto3-1.36.21 botocore-1.36.21 brotli-1.1.0 dacite-1.7.0 dill-0.3.9 fiftyone-1.3.0 fiftyone-brain-0.19.0 fiftyone-db-1.1.7 ftfy-6.3.1 graphql-core-3.2.6 hypercorn-0.17.3 inflate64-1.0.1 jmespath-1.0.1 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.29.1 motor-3.6.1 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.22.0 pybcj-1.0.3 pycryptodomex-3.21.0 pydash-8.0.5 pymongo-4.9.2 pyppmd-1.1.1 pyzstd-0.16.2 rarfile-4.2 retrying-1.3.4 rtree-1.3.0 s3transfer-0.11.2 sortedcontainers-2.4.0 sse-starlette-0.10.3 sseclient-py-1.8.0 starlette-0.45.3 strawberry-graphql-0.260.2 texttable-1.7.0 universal-analytics-python3-1.1.1 voxel51-eta-0.14.0 wsproto-1.2.0 xmltodict-0.14.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz"
      ],
      "metadata": {
        "id": "R2hLHZDGkEZI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The classes inside Coco Dataset\n",
        "|||||||||\n",
        "|:----|:----|:----|:----|:----|:----|:----|:----|\n",
        "|person|fire hydrant|elephant|skis|wine glass|broccoli|dining table|scissors|\n",
        "|toaster|bicycle|stop sign|bear|snowboard|cup|carrot|teddy bear|\n",
        "|toilet|sink|car|motorcycle|parking meter|bench|zebra|hair drier|\n",
        "|giraffe|sports ball|kite|fork|hot dog|tv|refrigerator|toothbrush|\n",
        "|knife|pizza|laptop|book|airplane|bird|backpack|baseball bat|\n",
        "|spoon|donut|mouse|clock|bus|cat|umbrella|baseball glove|\n",
        "|bowl|cake|remote|vase|train|dog|handbag|skateboard|\n",
        "|banana|chair|truck|horse|tie|surfboard|apple|couch|\n",
        "|boat|sheep|suitcase|tennis racket|sandwich|traffic light|COW|frisbee\n",
        "|bottle|orange|potted plant|bed|keyboard|cell phone|microwave|oven|\n",
        "\n",
        "\n",
        "This guides the class selection to make the dataset for this session"
      ],
      "metadata": {
        "id": "UTp6lZAd6Au9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Discovery\n",
        "\n",
        "## Reading the Data\n",
        "\n",
        "To access the CocoData dataset. The following code can be used to select individual categories one by one.\n",
        "\n",
        "```python\n",
        "dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",\n",
        "    label_types=[\"segmentations\"],\n",
        "    classes=[\"knife\", \"spoon\", \"bowl\",\n",
        "\"vase\", \"fork\", \"scissors\",\n",
        "\"dining table\"], # select parts of a dining room\n",
        "    max_samples=25,\n",
        ")\n",
        "```\n",
        "\n",
        "This example selects only the\n",
        "1. Knife\n",
        "2. Spoon\n",
        "3. Bowl\n",
        "4. Vase\n",
        "5. Fork\n",
        "6. Scissors\n",
        "\n",
        "\n",
        "## writing to local directory\n",
        "\n",
        "This is chosen for ease of read and permanence of data in the session\n",
        "\n",
        "## Challenge encountered\n",
        "\n",
        "```python\n",
        "labels_data['categories\n",
        "```\n",
        "\n",
        "Brings the following output\n",
        "\n",
        "```bash\n",
        "[{'id': 1, 'name': 'apple', 'supercategory': None},\n",
        " {'id': 2, 'name': 'backpack', 'supercategory': None},\n",
        " {'id': 3, 'name': 'banana', 'supercategory': None},\n",
        " {'id': 4, 'name': 'bed', 'supercategory': None},\n",
        " {'id': 5, 'name': 'bicycle', 'supercategory': None},\n",
        " {'id': 6, 'name': 'bird', 'supercategory': None},\n",
        " {'id': 7, 'name': 'book', 'supercategory': None},\n",
        " {'id': 8, 'name': 'bottle', 'supercategory': None},\n",
        " {'id': 9, 'name': 'bowl', 'supercategory': None},\n",
        " {'id': 10, 'name': 'broccoli', 'supercategory': None},\n",
        "...,\n",
        " {'id': 33, 'name': 'sink', 'supercategory': None},\n",
        " {'id': 34, 'name': 'spoon', 'supercategory': None},\n",
        " {'id': 35, 'name': 'tie', 'supercategory': None},\n",
        " {'id': 36, 'name': 'tv', 'supercategory': None},\n",
        " {'id': 37, 'name': 'vase', 'supercategory': None},\n",
        " {'id': 38, 'name': 'wine glass', 'supercategory': None}]\n",
        "```\n",
        "\n",
        "### Explanation of the Challenge\n",
        "\n",
        "The json file seems to be written up to the length ID of all the images of a particular category\n",
        "\n",
        "In this case because of the sampling max there are only 38 dining-related images that are selected and because of this only 38 labels are retrieved\n",
        "\n",
        "# Trying to Read the Whole Dataset\n",
        "\n",
        "This is to get exact labels"
      ],
      "metadata": {
        "id": "TuLhL8MKmHm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  Dataset of all the training data from CocoData\n",
        "\n",
        "\n",
        "train_dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split =\"train\")\n",
        "\n",
        "test_dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"test\"\n",
        ")\n",
        "val_dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qnbijRHqWw3",
        "outputId": "cc1b5384-ceca-41ec-f642-ad0abd6645e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    1.9Gb/1.9Gb [4.9s elapsed, 0s remaining, 411.0Mb/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    1.9Gb/1.9Gb [4.9s elapsed, 0s remaining, 411.0Mb/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading images to '/root/fiftyone/coco-2017/tmp-download/train2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading images to '/root/fiftyone/coco-2017/tmp-download/train2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |████|  144.1Gb/144.1Gb [6.9m elapsed, 0s remaining, 451.3Mb/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |████|  144.1Gb/144.1Gb [6.9m elapsed, 0s remaining, 451.3Mb/s]       \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images to '/root/fiftyone/coco-2017/train/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting images to '/root/fiftyone/coco-2017/train/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing annotations to '/root/fiftyone/coco-2017/train/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations to '/root/fiftyone/coco-2017/train/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'train'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████| 118287/118287 [12.8m elapsed, 0s remaining, 188.1 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████| 118287/118287 [12.8m elapsed, 0s remaining, 188.1 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-train' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-train' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'test' to '/root/fiftyone/coco-2017/test' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'test' to '/root/fiftyone/coco-2017/test' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading test info to '/root/fiftyone/coco-2017/tmp-download/image_info_test2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading test info to '/root/fiftyone/coco-2017/tmp-download/image_info_test2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    8.7Mb/8.7Mb [376.0ms elapsed, 0s remaining, 23.2Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    8.7Mb/8.7Mb [376.0ms elapsed, 0s remaining, 23.2Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting test info to '/root/fiftyone/coco-2017/raw/image_info_test2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting test info to '/root/fiftyone/coco-2017/raw/image_info_test2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading images to '/root/fiftyone/coco-2017/tmp-download/test2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading images to '/root/fiftyone/coco-2017/tmp-download/test2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████|   49.5Gb/49.5Gb [1.9m elapsed, 0s remaining, 451.7Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████|   49.5Gb/49.5Gb [1.9m elapsed, 0s remaining, 451.7Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images to '/root/fiftyone/coco-2017/test/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting images to '/root/fiftyone/coco-2017/test/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing annotations to '/root/fiftyone/coco-2017/test/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations to '/root/fiftyone/coco-2017/test/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'test'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'test'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████| 40670/40670 [14.6s elapsed, 0s remaining, 3.1K samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |█████████████| 40670/40670 [14.6s elapsed, 0s remaining, 3.1K samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-test' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-test' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Found annotations at '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading images to '/root/fiftyone/coco-2017/tmp-download/val2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Downloading images to '/root/fiftyone/coco-2017/tmp-download/val2017.zip'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |██████|    6.1Gb/6.1Gb [18.8s elapsed, 0s remaining, 211.5Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |██████|    6.1Gb/6.1Gb [18.8s elapsed, 0s remaining, 211.5Mb/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting images to '/root/fiftyone/coco-2017/validation/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Extracting images to '/root/fiftyone/coco-2017/validation/data'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing annotations to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.utils.coco:Writing annotations to '/root/fiftyone/coco-2017/validation/labels.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset info written to '/root/fiftyone/coco-2017/info.json'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Loading 'coco-2017' split 'validation'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |███████████████| 5000/5000 [30.4s elapsed, 0s remaining, 208.8 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:eta.core.utils: 100% |███████████████| 5000/5000 [30.4s elapsed, 0s remaining, 208.8 samples/s]      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 'coco-2017-validation' created\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:fiftyone.zoo.datasets:Dataset 'coco-2017-validation' created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read Direct"
      ],
      "metadata": {
        "id": "iz8Wzga_8s7M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbqTt5xQ2Nd8",
        "outputId": "49d0cf70-5aab-4285-a928-927f00c07231"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Name:        coco-2017-train\n",
              "Media type:  image\n",
              "Num samples: 118287\n",
              "Persistent:  False\n",
              "Tags:        []\n",
              "Sample fields:\n",
              "    id:               fiftyone.core.fields.ObjectIdField\n",
              "    filepath:         fiftyone.core.fields.StringField\n",
              "    tags:             fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
              "    metadata:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
              "    created_at:       fiftyone.core.fields.DateTimeField\n",
              "    last_modified_at: fiftyone.core.fields.DateTimeField\n",
              "    ground_truth:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trying a Permanent Data Write to save Memory"
      ],
      "metadata": {
        "id": "zN-tkDQG29TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DATASET_DIR = \"/content/drive/MyDrive/CocoData/Train\"\n",
        "TEST_DATASET_DIR = \"/content/drive/MyDrive/CocoData/Test\"\n",
        "VAL_DATASET_DIR = \"/content/drive/MyDrive/CocoData/Valid\""
      ],
      "metadata": {
        "id": "afre6qcf0JZM"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# write the dataset into a local directory called CocoData\n",
        "\n",
        "import os\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "if not os.path.exists(\"CocoData\"):\n",
        "    os.makedirs(\"CocoData\")\n",
        "\n",
        "# Export the dataset to the specified directory\n",
        "train_dataset.export(\n",
        "    export_dir=TRAIN_DATASET_DIR,\n",
        "    dataset_type=fo.types.COCODetectionDataset,\n",
        "    label_field=\"ground_truth\",\n",
        ")\n",
        "test_dataset.export(\n",
        "    export_dir=TEST_DATASET_DIR,\n",
        "    dataset_type=fo.types.COCODetectionDataset,\n",
        "    label_field=\"ground_truth\",\n",
        ")\n",
        "val_dataset.export(\n",
        "    export_dir=VAL_DATASET_DIR,\n",
        "    dataset_type=fo.types.COCODetectionDataset,\n",
        "    label_field=\"ground_truth\",\n",
        ")"
      ],
      "metadata": {
        "id": "whG2U-pGoLaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c381451b-3888-4e4b-d3d6-316741e17b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  33% |███\\-------|  39426/118287 [34.6m elapsed, 1.2h remaining, 18.2 samples/s]   "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# read a sample dataset"
      ],
      "metadata": {
        "id": "ZwjzndLsAILx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display image 000000001425 and it's label read from labels.json\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Assuming 'CocoData' directory is in the current working directory\n",
        "image_path = os.path.join(f\"{TRAIN_DATASET_DIR}data\", \"000000001425.jpg\")\n",
        "\n",
        "if os.path.exists(image_path):\n",
        "    img = mpimg.imread(image_path)\n",
        "    imgplot = plt.imshow(img)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"Error: Image file not found at {image_path}\")"
      ],
      "metadata": {
        "id": "9NAIDVOTC0RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Different Thought Process to Save on Memory\n",
        "\n",
        "## Initial Idea\n",
        "\n",
        "### Reading label name\n",
        "\n",
        "```python\n",
        "# extract the label for the above image from labels.json\n",
        "import json\n",
        "\n",
        "# Path to the labels.json file within the exported dataset\n",
        "labels_path = os.path.join(\"CocoData/Train\", \"labels.json\")\n",
        "\n",
        "if os.path.exists(labels_path):\n",
        "    with open(labels_path, \"r\") as f:\n",
        "        labels_data = json.load(f)\n",
        "\n",
        "    # Assuming the image ID is part of the filename\n",
        "    image_id = \"1425\"\n",
        "\n",
        "    # Iterate through the annotations to find the matching image ID\n",
        "    for annotation in labels_data[\"annotations\"]:\n",
        "        if annotation[\"image_id\"] == int(image_id):\n",
        "            # Assuming 'category_id' maps to a category in the 'categories' section\n",
        "            category_id = annotation[\"category_id\"]\n",
        "            for category in labels_data[\"categories\"]:\n",
        "                if category[\"id\"] == category_id:\n",
        "                    print(f\"Label for image {image_id}: {category['name']}\")\n",
        "                    break  # Exit the inner loop once the label is found\n",
        "            break  # Exit the outer loop once the matching annotation is found\n",
        "else:\n",
        "    print(f\"Error: labels.json file not found at {labels_path}\")\n",
        "```"
      ],
      "metadata": {
        "id": "y4LWl3Q209ji"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gFVjlW_qiDHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reading the .json file"
      ],
      "metadata": {
        "id": "IAGQ9mvE1R1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Read the whole labels.json file\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Path to the labels.json file within the exported dataset\n",
        "labels_path = os.path.join(\"CocoData/Train\", \"labels.json\")\n",
        "\n",
        "if os.path.exists(labels_path):\n",
        "    with open(labels_path, \"r\") as f:\n",
        "        labels_data = json.load(f)\n",
        "    print(labels_data)\n",
        "else:\n",
        "    print(f\"Error: labels.json file not found at {labels_path}\")"
      ],
      "metadata": {
        "id": "ZUJSn--ei72f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: Convert the labels_data to a dictionary\n",
        "\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Path to the labels.json file within the exported dataset\n",
        "train_labels_path = os.path.join(\"CocoData/Train\", \"labels.json\")\n",
        "test_labels_path = os.path.join(\"CocoData/Test\", \"labels.json\")\n",
        "val_labels_path = os.path.join(\"CocoData/Valid\", \"labels.json\")\n",
        "\n",
        "if os.path.exists(labels_path):\n",
        "    with open(labels_path, \"r\") as f:\n",
        "        labels_data = json.load(f)\n",
        "\n",
        "    # Convert the JSON data to a dictionary (it already is)\n",
        "    labels_dict = labels_data\n",
        "    print(labels_dict)\n",
        "\n",
        "else:\n",
        "    print(f\"Error: labels.json file not found at {labels_path}\")"
      ],
      "metadata": {
        "id": "UFjSdpFIjsyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Explore the Data Labels"
      ],
      "metadata": {
        "id": "e5d5CnnHkqJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_path['info']"
      ],
      "metadata": {
        "id": "9GADqZ7Aj9zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_path['licenses']"
      ],
      "metadata": {
        "id": "nYApHfk3kyk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels_path['categories']"
      ],
      "metadata": {
        "id": "499iJdMJlY9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels_data['categories'])"
      ],
      "metadata": {
        "id": "aw6NSXLOl03f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the model"
      ],
      "metadata": {
        "id": "nbB2mrsPhe7z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "tuns0yRmhiPU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LABELS_FILE = f\"{TRAIN_DATASET_DIR}/labels.json\"\n",
        "DATASET_DIR = f\"{TRAIN_DATASET_DIR}/data\"\n",
        "with open(LABELS_FILE, \"r\") as f:\n",
        "    coco_data = json.load(f)"
      ],
      "metadata": {
        "id": "EHgTtHQz_-5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Extract Categories"
      ],
      "metadata": {
        "id": "IWg21UhfAr3K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "categories = {cat[\"id\"]: cat[\"name\"] for cat in coco_data[\"categories\"]}"
      ],
      "metadata": {
        "id": "X3whLTppAntX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save the Classes"
      ],
      "metadata": {
        "id": "uVu2-W_-A4-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_DIR = \"CocoData/Formatted_Train\"\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)\n",
        "\n",
        "for cat_name in categories.values():\n",
        "    class_path = os.path.join(OUTPUT_DIR, cat_name)\n",
        "    os.makedirs(class_path, exist_ok=True)"
      ],
      "metadata": {
        "id": "xTib0YwPAvDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Organize the Images to their Categories"
      ],
      "metadata": {
        "id": "N-69nARDBOAv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "image_id_to_file = {img[\"id\"]: img[\"file_name\"] for img in coco_data[\"images\"]}\n",
        "\n",
        "for ann in coco_data[\"annotations\"]:\n",
        "    img_id = ann[\"image_id\"]\n",
        "    category_id = ann[\"category_id\"]\n",
        "\n",
        "    img_filename = image_id_to_file.get(img_id)\n",
        "    if not img_filename:\n",
        "        continue\n",
        "\n",
        "    src_path = os.path.join(DATASET_DIR, \"data\", img_filename)\n",
        "    dest_path = os.path.join(OUTPUT_DIR, categories[category_id], img_filename)\n",
        "\n",
        "    if os.path.exists(src_path):\n",
        "        shutil.copy(src_path, dest_path)"
      ],
      "metadata": {
        "id": "Oc8z_CrgBSMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Image Data Generator"
      ],
      "metadata": {
        "id": "InMbhuVxBZP7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    OUTPUT_DIR,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "val_generator = train_datagen.flow_from_directory(\n",
        "    OUTPUT_DIR,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "id": "7whMXXFsBeN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using InceptionV3 model"
      ],
      "metadata": {
        "id": "bOQrWkzcBoYl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "UW9vWb7sBuMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Classification Head"
      ],
      "metadata": {
        "id": "RN-bFP0HB16D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dense(len(categories), activation='softmax')"
      ],
      "metadata": {
        "id": "Gi0n49VEBx2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The Model"
      ],
      "metadata": {
        "id": "Of2v0YvFCAvD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "paztX811B97y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=10,\n",
        "    validation_data=val_generator\n",
        ")"
      ],
      "metadata": {
        "id": "qmGHDB0ACOSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save the coco data model trained through transfer learning"
      ],
      "metadata": {
        "id": "WVvYslakCS7S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_generator)\n",
        "model.save(\"inception_coco_classifier.keras\")"
      ],
      "metadata": {
        "id": "LRiDqjzXCjf7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}