{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO+QBsa6ULKNRU4zf+7yVjb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dnzambuli/Deep-learning-4-CV/blob/master/Contrastive_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  Objective\n",
        "The goal of this lab is to understand how contrastive learning works by implementing SimCLR,\n",
        "a self-supervised learning framework. You will:\n",
        "\n",
        "1. Apply data augmentation techniques to create positive pairs.\n",
        "2. Train a neural network using contrastive loss.\n",
        "3. Fine-tune the pretrained model on a classification task.\n",
        "4. Evaluate the effectiveness of contrastive learning.\n",
        "\n",
        "## Libraries\n",
        "üêç python (>=3.7)\n",
        "\n",
        "üî¶ PyTorch\n",
        "\n",
        "üî¶ üëÅ torchvision\n",
        "\n",
        "ü§î NumPy\n",
        "\n",
        "„ÄΩ Matplotlib\n",
        "\n",
        "üßë scikit-learn\n",
        "\n",
        "# Step 1: Load and Preprocess the Dataset"
      ],
      "metadata": {
        "id": "PkckS86Rzfgo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bx_nLRt4zF8q",
        "outputId": "ad1709cc-2c92-46d4-88a0-a721a1f6a2d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 170M/170M [00:54<00:00, 3.11MB/s]\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "# Define data augmentations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(32),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomApply([transforms.ColorJitter(0.8, 0.8, 0.8, 0.2)],\n",
        "                           p=0.8),\n",
        "    transforms.RandomGrayscale(p=0.2),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                             transform=train_transform, download=True)\n",
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True,\n",
        "                          num_workers=4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Define the SimCLR Model"
      ],
      "metadata": {
        "id": "XwJJSR5t0VzR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "class SimCLR(nn.Module):\n",
        "  def __init__(self, base_model='resnet18', projection_dim=128):\n",
        "    super(SimCLR, self).__init__()\n",
        "    self.encoder = models.resnet18(pretrained=False)\n",
        "    self.encoder.fc = nn.Identity() # Remove classification head\n",
        "    # Projection head\n",
        "    self.projection_head = nn.Sequential(\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, projection_dim)\n",
        "        )\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.projection_head(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "v-Vh-d2r0c-g"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 3: Define the Contrastive Loss (NT-Xent Loss)\n",
        "\n",
        "The **Normalized Temperature-scaled Cross-Entropy Loss (NT-Xent)** is used for contrastive\n",
        "learning"
      ],
      "metadata": {
        "id": "B_slZ7zM0ySC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "def contrastive_loss(out_1, out_2, temperature=0.5):\n",
        "  # Normalize embeddings\n",
        "  out_1 = F.normalize(out_1, dim=1)\n",
        "  out_2 = F.normalize(out_2, dim=1)\n",
        "  # Compute similarity scores\n",
        "  batch_size = out_1.shape[0]\n",
        "  labels = torch.arange(batch_size).cuda()\n",
        "\n",
        "  similarity_matrix = torch.mm(out_1, out_2.T) / temperature\n",
        "  loss = F.cross_entropy(similarity_matrix, labels)\n",
        "  return loss"
      ],
      "metadata": {
        "id": "Ic8zDysw03vY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 4: Train the SimCLR Model\n",
        "Train the model using contrastive loss."
      ],
      "metadata": {
        "id": "aOzz1BlW1CDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "# Initialize model and optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"t4\")\n",
        "model = SimCLR().to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  for (images, _) in train_loader:\n",
        "    images = images.to(device)\n",
        "\n",
        "    # Generate two augmented views\n",
        "    # The train_transform is called on the CPU\n",
        "    # before moving to the device to avoid the error\n",
        "    images_1 = torch.stack([train_transform(transforms.ToPILImage()(image.cpu())) for image in images]).to(device)\n",
        "    images_2 = torch.stack([train_transform(transforms.ToPILImage()(image.cpu())) for image in images]).to(device)\n",
        "\n",
        "\n",
        "\n",
        "    # Forward pass\n",
        "    out_1 = model(images_1)\n",
        "    out_2 = model(images_2)\n",
        "\n",
        "    # Compute loss\n",
        "    loss = contrastive_loss(out_1, out_2)\n",
        "\n",
        "    # Backpropagation\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ah2dYaAh1FAY",
        "outputId": "062654e3-aadd-43f3-9067-9b6c6a3f1c55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/100], Loss: 3.6999\n",
            "Epoch [2/100], Loss: 3.6923\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 5: Transfer Learning and Evaluation\n",
        "Fine-tune the pretrained model for classification."
      ],
      "metadata": {
        "id": "cQqhSs8i1bM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 test dataset\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    ])\n",
        "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                            transform=test_transform, download=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False,\n",
        "                         num_workers=4)\n",
        "# Define classifier\n",
        "class Classifier(nn.Module):\n",
        "  def __init__(self, base_model):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.encoder = base_model.encoder # Use pretrained encoder\n",
        "    self.fc = nn.Linear(512, 10) # 10 classes in CIFAR-10\n",
        "  def forward(self, x):\n",
        "    x = self.encoder(x)\n",
        "    x = self.fc(x)\n",
        "    return x\n",
        "# Initialize classifier\n",
        "classifier = Classifier(model).to(device)\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=3e-4)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Training classifier\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "  classifier.train()\n",
        "  for (images, labels) in train_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "    outputs = classifier(images)\n",
        "    loss = criterion(outputs, labels)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}\")\n",
        "# Evaluate classifier\n",
        "classifier.eval()\n",
        "correct, total = 0, 0\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    outputs = classifier(images)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "  accuracy = 100 * correct / total\n",
        "  print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "9tgIZo1w1d-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 6: Analysis and Interpretation\n",
        "1. Compare the test accuracy of the classifier when trained:\n",
        "o From scratch\n",
        "o With contrastive learning pretraining\n",
        "2. Visualize learned embeddings using t-SNE."
      ],
      "metadata": {
        "id": "Tcvc65PL3SeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# Extract embeddings\n",
        "classifier.eval()\n",
        "embeddings, labels_list = [], []\n",
        "with torch.no_grad():\n",
        "  for images, labels in test_loader:\n",
        "    images, labels = images.to(device), labels.to(device)\n",
        "    features = classifier.encoder(images)\n",
        "    embeddings.append(features.cpu().numpy())\n",
        "    labels_list.append(labels.cpu().numpy())\n",
        "# Convert to numpy\n",
        "embeddings = np.concatenate(embeddings, axis=0)\n",
        "labels_list = np.concatenate(labels_list, axis=0)\n",
        "# Reduce dimensions\n",
        "tsne = TSNE(n_components=2, perplexity=30, random_state=42)\n",
        "embeddings_2d = tsne.fit_transform(embeddings)\n",
        "# Plot embeddings\n",
        "plt.figure(figsize=(10, 6))\n",
        "scatter = plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1],\n",
        "c=labels_list, cmap='tab10', alpha=0.7)\n",
        "plt.legend(*scatter.legend_elements(), title=\"Classes\")\n",
        "plt.title(\"t-SNE Visualization of Embeddings\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0SyplN2U3Wdh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}